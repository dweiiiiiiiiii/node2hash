{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from datasets import *\n",
    "from utils import *\n",
    "from scipy import sparse\n",
    "\n",
    "from model.EdgeReg import *\n",
    "from model.EdgeReg_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpunum = \"2\"\n",
    "nbits = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpunum\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1\n",
    "\n",
    "dataset_name = 'pubmed'\n",
    "data_dir = os.path.join('dataset/clean', dataset_name)\n",
    "\n",
    "train_batch_size=100\n",
    "test_batch_size=100\n",
    "\n",
    "train_set = TextDataset(dataset_name, data_dir, subset='train')\n",
    "test_set = TextDataset(dataset_name, data_dir, subset='test')\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=train_batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dim = train_set.num_classes()\n",
    "num_bits = nbits\n",
    "num_features = train_set[0][1].size(0)\n",
    "num_nodes = len(train_set)\n",
    "edge_weight = 1.0\n",
    "dropout_prob = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_samples == 1:\n",
    "    model = EdgeReg(dataset_name, num_features, num_nodes, num_bits, dropoutProb=dropout_prob, device=device)\n",
    "else:\n",
    "    print(\"number of samples (T) = {}\".format(num_samples))\n",
    "    model = EdgeReg_v2(dataset_name, num_features, num_nodes, num_bits, dropoutProb=dropout_prob, device=device, T=num_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeReg(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=500, out_features=1000, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "    (3): ReLU(inplace)\n",
       "    (4): Dropout(p=0.1)\n",
       "  )\n",
       "  (h_to_mu): Linear(in_features=1000, out_features=128, bias=True)\n",
       "  (h_to_logvar): Sequential(\n",
       "    (0): Linear(in_features=1000, out_features=128, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=500, bias=True)\n",
       "    (1): LogSoftmax()\n",
       "  )\n",
       "  (nn_decoder): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=18230, bias=True)\n",
       "    (1): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if num_samples == 1:\n",
    "    saved_model_file = 'saved_models/node2hash.{}.T{}.bit{}.pth'.format(dataset_name, num_samples, nbits)\n",
    "else:\n",
    "    saved_model_file = 'saved_models/node2hash_v2.{}.T{}.bit{}.pth'.format(dataset_name, num_samples, nbits)\n",
    "\n",
    "model.load_state_dict(torch.load(saved_model_file))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average prec at 100 = 0.7731\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# get non-binary code\n",
    "with torch.no_grad():\n",
    "    train_zy = [(model.encode(xb.to(model.device))[0], yb) for _, xb, yb, _ in train_loader]\n",
    "    train_z, train_y = zip(*train_zy)\n",
    "    train_z = torch.cat(train_z, dim=0)\n",
    "    train_y = torch.cat(train_y, dim=0)\n",
    "    \n",
    "    test_zy = [(model.encode(xb.to(model.device))[0], yb) for _, xb, yb, _ in test_loader]\n",
    "    test_z, test_y = zip(*test_zy)\n",
    "    test_z = torch.cat(test_z, dim=0)\n",
    "    test_y = torch.cat(test_y, dim=0)\n",
    "    \n",
    "    train_z_batch = train_z.unsqueeze(-1).transpose(2,0)\n",
    "    test_z_batch = test_z.unsqueeze(-1)\n",
    "    \n",
    "    # compute cosine similarity\n",
    "    dist = F.cosine_similarity(test_z_batch, train_z_batch, dim=1)\n",
    "    ranklist = torch.argsort(dist, dim=1, descending=True)\n",
    "    top100 = ranklist[:, :100]\n",
    "    \n",
    "    prec_at_100 = []\n",
    "    for eval_index in range(0, test_y.size(0)):\n",
    "        top100_labels = torch.index_select(train_y.to(device), 0, top100[eval_index]).type(torch.cuda.ByteTensor)\n",
    "        groundtruth_label = test_y[eval_index].type(torch.cuda.ByteTensor)\n",
    "        matches = (groundtruth_label.unsqueeze(0) & top100_labels).sum(dim=1) > 0\n",
    "        num_corrects = matches.sum().type(torch.cuda.FloatTensor)\n",
    "        prec_at_100.append((num_corrects/100.).item())   \n",
    "\n",
    "    print('average prec at 100 = {:.4f}'.format(np.mean(prec_at_100)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Research2018",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
