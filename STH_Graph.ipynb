{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm import *\n",
    "import os\n",
    "import sklearn.preprocessing\n",
    "from utils import *\n",
    "from graph_utils import *\n",
    "from rank_metrics import *\n",
    "\n",
    "import time\n",
    "\n",
    "params = get_cmdline_params()\n",
    "model_name = \"STHgraph_{}_{}_step{}\".format(params.walk_type, params.modelinfo, params.walk_steps)\n",
    "\n",
    "##################################################################################################\n",
    "\n",
    "nameManager = createGraphNameManager(params.dataset)\n",
    "data = Load_Graph_Dataset(nameManager.bow_fn)\n",
    "\n",
    "print('num train:{}'.format(data.n_trains))\n",
    "print('num test:{}'.format(data.n_tests))\n",
    "print('num vocabs:{}'.format(data.n_feas))\n",
    "print('num labels:{}'.format(data.n_tags))\n",
    "\n",
    "##################################################################################################\n",
    "\n",
    "train_graph = GraphData(nameManager.train_graph)\n",
    "test_graph = GraphData(nameManager.test_graph)\n",
    "    \n",
    "#################################################################################################\n",
    "\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "class STH:\n",
    "    def __init__(self, num_bits):\n",
    "        super(STH, self).__init__()\n",
    "        \n",
    "        self.num_bits = num_bits\n",
    "        self.clfs = [LinearSVC() for n in range(num_bits)]\n",
    "        \n",
    "    def create_weight_matrix(self, train_mat, num_train, graph):\n",
    "        columns = []\n",
    "        rows = []\n",
    "        weights = []\n",
    "        for node_id in range(num_train):\n",
    "            col = graph.graph[node_id]\n",
    "            #col = DFS_walk(graph, node_id, 20)\n",
    "            #col = second_order_neighbor_walk(graph, node_id)\n",
    "            #print(node_id)\n",
    "            if len(col) <= 0:\n",
    "                col = [node_id]\n",
    "            #assert(len(col) > 0)\n",
    "                \n",
    "            row = [node_id] * len(col)\n",
    "            w = cosine_similarity(train_mat[node_id], train_mat[col])\n",
    "            #w = [[0.9] * len(col)]\n",
    "\n",
    "            columns += col\n",
    "            rows += row\n",
    "            weights += list(w[0])\n",
    "\n",
    "        W = coo_matrix((weights, (rows, columns)), shape=(num_train, num_train))\n",
    "        return W\n",
    "    \n",
    "    def fit_transform(self, train_mat, num_train, graph):\n",
    "        W = self.create_weight_matrix(train_mat, num_train, graph)\n",
    "        D = np.asarray(W.sum(axis=1)).squeeze() + 0.0001 # adding damping value for a numerical stabability\n",
    "        D = scipy.sparse.diags(D)\n",
    "        L = D - W\n",
    "    \n",
    "        L = scipy.sparse.csc_matrix(L)\n",
    "        D = scipy.sparse.csc_matrix(D)\n",
    "\n",
    "        num_attempts = 0\n",
    "        max_attempts = 3\n",
    "        success = False\n",
    "        \n",
    "        while not success:\n",
    "            E, Y = eigsh(L, k=self.num_bits+1, M=D, which='SM')\n",
    "            success = np.all(np.isreal(Y))\n",
    "            \n",
    "            if not success:\n",
    "                print(\"Warning: Some eigenvalues are not real values. Retry to solve Eigen-decomposition.\")\n",
    "                num_attempts += 1\n",
    "            \n",
    "            if num_attempts > max_attempts:\n",
    "                assert(np.all(np.isreal(Y))) # if this fails, re-run fit again\n",
    "                assert(False) # Check your data \n",
    "        \n",
    "        Y = np.real(Y)\n",
    "        Y = Y[:, 1:]\n",
    "        \n",
    "        medHash = MedianHashing()\n",
    "        cbTrain = medHash.fit_transform(Y)    \n",
    "        for b in range(0, cbTrain.shape[1]):\n",
    "            self.clfs[b].fit(train_mat, cbTrain[:, b])\n",
    "        return cbTrain\n",
    "    \n",
    "    def transform(self, test_mat, num_test):\n",
    "        cbTest = np.zeros((num_test, self.num_bits), dtype=np.int64)\n",
    "        for b in range(0, self.num_bits):\n",
    "            cbTest[:,b] = self.clfs[b].predict(test_mat)\n",
    "        return cbTest\n",
    "   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=params.gpu_num\n",
    "\n",
    "sth_model = STH(params.nbits)\n",
    "\n",
    "cbTrain = sth_model.fit_transform(data.train, data.n_trains, train_graph)\n",
    "cbTest = sth_model.transform(data.test, data.n_tests)\n",
    "\n",
    "gnd_train = data.gnd_train.toarray()\n",
    "gnd_test = data.gnd_test.toarray()\n",
    "\n",
    "eval_results = DotMap()\n",
    "\n",
    "top_k_indices = retrieveTopKDoc(cbTrain, cbTest, batchSize=params.test_batch_size, TopK=100)\n",
    "relevances = countNumRelevantDoc(gnd_train, gnd_test, top_k_indices)\n",
    "relevances = relevances.cpu().numpy()\n",
    "\n",
    "eval_results.ndcg_at_5 = np.mean([ndcg_at_k(r, 5) for r in relevances[:, :5]])\n",
    "eval_results.ndcg_at_10 = np.mean([ndcg_at_k(r, 10) for r in relevances[:, :10]])\n",
    "eval_results.ndcg_at_20 = np.mean([ndcg_at_k(r, 20) for r in relevances[:, :20]])\n",
    "eval_results.ndcg_at_50 = np.mean([ndcg_at_k(r, 50) for r in relevances[:, :50]])\n",
    "eval_results.ndcg_at_100 = np.mean([ndcg_at_k(r, 100) for r in relevances[:, :100]])\n",
    "\n",
    "relevances = (relevances > 0)\n",
    "eval_results.prec_at_5 = np.mean(np.sum(relevances[:, :5], axis=1)) / 100\n",
    "eval_results.prec_at_10 = np.mean(np.sum(relevances[:, :10], axis=1)) / 100\n",
    "eval_results.prec_at_20 = np.mean(np.sum(relevances[:, :20], axis=1)) / 100\n",
    "eval_results.prec_at_50 = np.mean(np.sum(relevances[:, :50], axis=1)) / 100\n",
    "eval_results.prec_at_100 = np.mean(np.sum(relevances[:, :100], axis=1)) / 100\n",
    "\n",
    "best_results = EvalResult(eval_results)\n",
    "\n",
    "print('*' * 80)\n",
    "model_name = \"STH_graph\"\n",
    "if params.save:\n",
    "    import scipy.io\n",
    "    data_path = os.path.join(os.environ['HOME'], 'projects/graph_embedding/save_bincode', params.dataset)\n",
    "    save_fn = os.path.join(data_path, '{}.bincode.{}.mat'.format(model_name, params.nbits))\n",
    "\n",
    "    print(\"save the binary code to {} ...\".format(save_fn))\n",
    "    cbTrain = sth_model.fit_transform(data.train, data.n_trains, train_graph)\n",
    "    cbTest = sth_model.transform(data.test, data.n_tests)\n",
    "    \n",
    "    scipy.io.savemat(save_fn, mdict={'train': cbTrain, 'test': cbTest})\n",
    "    print('save data to {}'.format(save_fn))\n",
    "\n",
    "if params.save_results:\n",
    "    fn = \"results/{}/results.{}.csv\".format(params.dataset, params.nbits)\n",
    "    save_eval_results(fn, model_name, best_results)\n",
    "\n",
    "print('*' * 80)\n",
    "print(\"{}\".format(model_name))\n",
    "\n",
    "metrics = ['prec_at_{}'.format(n) for n in ['5', '10', '20', '50', '100']]\n",
    "prec_results = \",\".join([\"{:.3f}\".format(best_results.best_scores[metric]) for metric in metrics])\n",
    "print(\"prec: {}\".format(prec_results))\n",
    "\n",
    "metrics = ['ndcg_at_{}'.format(n) for n in ['5', '10', '20', '50', '100']]\n",
    "ndcg_results = \",\".join([\"{:.3f}\".format(best_results.best_scores[metric]) for metric in metrics])\n",
    "print(\"ndcg: {}\".format(ndcg_results))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Research2018",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
