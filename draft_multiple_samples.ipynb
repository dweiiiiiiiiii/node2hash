{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from datasets import *\n",
    "from utils import *\n",
    "from model.EdgeReg import *\n",
    "from model.EdgeReg_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'toarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e6f0fc178ae3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0my_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mnum_bits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mnum_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mnum_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0medge_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/home/schaidaroon/research/node2hash/datasets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mlabel_bow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_bow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_bow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_bow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'toarray'"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "dataset_name = \"ng20\"\n",
    "data_dir = os.path.join('dataset/clean', dataset_name)\n",
    "\n",
    "train_batch_size=100\n",
    "test_batch_size=100\n",
    "\n",
    "train_set = TextDataset(dataset_name, data_dir, subset='train')\n",
    "test_set = TextDataset(dataset_name, data_dir, subset='test')\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=train_batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=test_batch_size, shuffle=True)\n",
    "\n",
    "#########################################################################################################\n",
    "y_dim = train_set.num_classes()\n",
    "num_bits = 32\n",
    "num_features = train_set[0][1].size(0)\n",
    "num_nodes = len(train_set)\n",
    "edge_weight = 1.0\n",
    "\n",
    "# print(\"Train node2hash model ...\")\n",
    "# print(\"dataset: {}\".format(args.dataset))\n",
    "# print(\"numbits: {}\".format(args.nbits))\n",
    "# print(\"gpu id:  {}\".format(args.gpunum))\n",
    "# print(\"dropout probability: {}\".format(args.dropout))\n",
    "# print(\"num epochs: {}\".format(args.num_epochs))\n",
    "# print(\"learning rate: {}\".format(args.lr))\n",
    "# print(\"num train: {} num test: {}\".format(len(train_set), len(test_set)))\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "walk_type, max_nodes = \"BFS-20\".split('-') #args.walk.split('-')\n",
    "max_nodes = int(max_nodes)\n",
    "print(\"Walk type: {} with maximum nodes of: {}\".format(walk_type, max_nodes))\n",
    "\n",
    "if walk_type == 'BFS':\n",
    "    neighbor_sample_func = BFS_walk\n",
    "elif walk_type == 'DFS':\n",
    "    neighbor_sample_func = DFS_walk\n",
    "elif walk_type == 'Random':\n",
    "    neighbor_sample_func = Random_walk\n",
    "else:\n",
    "    neighbor_sample_func = None\n",
    "    print(\"The model will only takes the immediate neighbors.\")\n",
    "    #assert(False), \"unknown walk type (has to be one of the following: BFS, DFS, Random)\"\n",
    "\n",
    "def get_neighbors(ids, df, max_nodes, batch_size, traversal_func):\n",
    "    cols = []\n",
    "    rows = []\n",
    "    for idx, node_id in enumerate(ids):\n",
    "        col = traversal_func(df, node_id.item(), max_nodes)\n",
    "        rows += [idx] * len(col)\n",
    "        cols += col\n",
    "    data = [1] * len(cols)\n",
    "    connections = sparse.csr_matrix((data, (rows, cols)), shape=(batch_size, len(df)))\n",
    "    return torch.from_numpy(connections.toarray()).type(torch.FloatTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EdgeReg_v2(dataset_name, num_features, num_nodes, \n",
    "                   num_bits, dropoutProb=0.1, device=device, T=5)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, (ids, xb, yb, nb) in tqdm(enumerate(train_loader), ncols=50, total=len(train_loader)):\n",
    "    xb = xb.to(device)\n",
    "    yb = yb.to(device)\n",
    "\n",
    "    if neighbor_sample_func is not None:\n",
    "        nb = get_neighbors(ids, train_set.df, max_nodes, xb.size(0), neighbor_sample_func)\n",
    "    nb = nb.to(device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprob_w, logprob_nn, mu, logvar = model(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_loss = EdgeReg.calculate_KL_loss(mu, logvar)\n",
    "kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstr_loss = EdgeReg_v2.compute_reconstr_loss(logprob_w, xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_reconstr_loss = EdgeReg_v2.compute_edge_reconstr_loss(logprob_nn, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_reconstr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = mu.new_empty((mu.size(0), T, mu.size(1))).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = torch.sqrt(torch.exp(logvar))\n",
    "std = std.unsqueeze(1)\n",
    "mu = mu.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = eps.mul(std).add_(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob_w = model.decoder(z.view(-1, 32))\n",
    "log_prob_w = log_prob_w.view(batch_size, T, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_w.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-torch.mean(torch.sum(log_prob_w * xb.unsqueeze(1), dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = torch.cuda.FloatTensor(mu.size()).normal_()\n",
    "eps.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparametrize(self, mu, logvar):\n",
    "        std = torch.sqrt(torch.exp(logvar))\n",
    "        eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Research2018",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
