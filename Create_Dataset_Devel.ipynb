{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'reuters'\n",
    "data_dir = os.path.join('../VDSH/dataset/', dataset_name)\n",
    "fn = 'train.NN.pkl'\n",
    "train_df = pd.read_pickle(os.path.join(data_dir, fn))\n",
    "\n",
    "num_trains = len(train_df)\n",
    "bows_mat = sparse.vstack(list(train_df.bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name in ['ng20']:\n",
    "    # convert the label to a sparse matrix\n",
    "    labels = list(train_df.label)\n",
    "    num_labels = (np.max(labels) - np.min(labels)) + 1\n",
    "    one_hot_mat = np.eye(num_labels, dtype=int)\n",
    "    label_mat = sparse.csr_matrix(one_hot_mat[labels])\n",
    "else:\n",
    "    label_mat = sparse.vstack(list(train_df.label))\n",
    "    num_labels = label_mat.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = cosine_similarity(bows_mat, bows_mat)\n",
    "indices = np.argsort(-dist, axis=1)\n",
    "\n",
    "docid2index = {docid: index for index, docid in enumerate(list(train_df.index))}\n",
    "index2docid = {index: docid for index, docid in enumerate(list(train_df.index))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools \n",
    "top_nn = list(map(lambda v: index2docid[v], indices.reshape(-1)))\n",
    "top_nn = np.array(top_nn).reshape(num_trains, num_trains)\n",
    "assert(np.all([v in train_df.index for v in top_nn[:, 0]])) # makesure all docid does exist in the train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'doc_id': list(train_df.index),\n",
    "        'bow': list(train_df.bow),\n",
    "        'label': [arr for arr in label_mat],\n",
    "        'neighbors': [list(arr) for arr in top_nn[:, 1:101]]}\n",
    "\n",
    "new_df = pd.DataFrame.from_dict(data)\n",
    "new_df.set_index('doc_id', inplace=True)\n",
    "\n",
    "new_df.to_pickle('dataset/clean/{}/{}.train.pkl'.format(dataset_name, dataset_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../VDSH/dataset/{}'.format(dataset_name)\n",
    "fn = 'test.NN.pkl'\n",
    "test_df = pd.read_pickle(os.path.join(data_dir, fn))\n",
    "\n",
    "num_tests = len(test_df)\n",
    "test_bows_mat = sparse.vstack(list(test_df.bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name in ['ng20']:\n",
    "    # convert the label to a sparse matrix\n",
    "    labels = list(test_df.label)\n",
    "    label_mat = sparse.csr_matrix(one_hot_mat[labels])\n",
    "else:\n",
    "    label_mat = sparse.vstack(list(test_df.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = cosine_similarity(test_bows_mat, bows_mat)\n",
    "indices = np.argsort(-dist, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_nn = list(map(lambda v: index2docid[v], indices.reshape(-1)))\n",
    "top_nn = np.array(top_nn).reshape(num_tests, num_trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'doc_id': list(test_df.index),\n",
    "        'bow': list(test_df.bow),\n",
    "        'label': [arr for arr in label_mat],\n",
    "        'neighbors': [list(arr) for arr in top_nn[:, :100]]}\n",
    "\n",
    "new_df = pd.DataFrame.from_dict(data)\n",
    "new_df.set_index('doc_id', inplace=True)\n",
    "\n",
    "new_df.to_pickle('dataset/clean/{}/{}.test.pkl'.format(dataset_name, dataset_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Research2018",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
