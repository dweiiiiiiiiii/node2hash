{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train: 2312 num test: 1000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "\n",
    "dataset_name = 'citeseer'\n",
    "data_dir = os.path.join('../dataset/raw', dataset_name)\n",
    "fn = os.path.join(data_dir, 'ind.{}.mat'.format(dataset_name))\n",
    "data = scipy.io.loadmat(fn)\n",
    "\n",
    "n_train = data['all_x'].shape[0]\n",
    "n_test = data['tx'].shape[0]\n",
    "test_indices = np.squeeze(data['test_idx'])\n",
    "\n",
    "print('num train: {} num test: {}'.format(n_train, n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "testIds = set(test_indices)\n",
    "\n",
    "#Remove any test node that only links to the test nodes\n",
    "def load_graph(fn):\n",
    "    graph = {}\n",
    "\n",
    "    with open(fn) as in_csv:\n",
    "        for line in in_csv:\n",
    "            tokens = line.strip().split(',')\n",
    "            nodeIDs = [int(t) for t in tokens]\n",
    "            key = nodeIDs[0]\n",
    "            neighbors = nodeIDs[1:]\n",
    "            graph[key] = neighbors\n",
    "    return graph\n",
    "\n",
    "graph_fn = os.path.join(data_dir, 'ind.{}.graph.csv'.format(dataset_name))\n",
    "gp = load_graph(graph_fn)\n",
    "\n",
    "# Graph should contain the same number of train data as all_x\n",
    "train_indices = [key for key in gp if key not in testIds and key < n_train]\n",
    "assert(len(train_indices) == n_train)\n",
    "\n",
    "# get valid train indices\n",
    "train_indices = [key for key in gp if key not in testIds]\n",
    "extra_train_indices = [idx for idx in train_indices if idx >= n_train]\n",
    "#print(len(train_indices))\n",
    "#print(len(extra_train_indices))\n",
    "train_indices = [idx for idx in train_indices if idx not in extra_train_indices]\n",
    "#print(len(train_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train: 2312\n",
      "total valid train: 1983\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################\n",
    "valid_train_nodes = []\n",
    "for nodeId in train_indices:    \n",
    "    vertices = gp[nodeId]\n",
    "    num_nodes = len(vertices)\n",
    "    num_test_nodes = len([v for v in vertices if v in testIds or v in extra_train_indices])\n",
    "    \n",
    "    if num_nodes > num_test_nodes:\n",
    "        valid_train_nodes.append(nodeId)\n",
    "        \n",
    "print('total train: {}'.format(n_train))\n",
    "print('total valid train: {}'.format(len(valid_train_nodes)))\n",
    "\n",
    "# figure out the trainId to keep (starting from 0)\n",
    "valid_train_ids = [idx for idx, trainId in enumerate(train_indices) if trainId in valid_train_nodes]\n",
    "assert(len(valid_train_nodes) == len(valid_train_ids))\n",
    "\n",
    "# filter the test data and labels\n",
    "train_data = data['all_x'][valid_train_ids, :]\n",
    "train_labels = data['all_y'][valid_train_ids, :]\n",
    "assert(train_data.shape[0] == train_labels.shape[0] == len(valid_train_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total test: 1000\n",
      "total valid test: 670\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################\n",
    "valid_test_nodes = []\n",
    "for testId in test_indices:\n",
    "    vertices = gp[testId]\n",
    "    \n",
    "    num_nodes = len(vertices)\n",
    "    num_valid_train_nodes = len([v for v in vertices if v in set(valid_train_ids)])\n",
    "    \n",
    "    if num_valid_train_nodes > 0:\n",
    "        valid_test_nodes.append(testId)\n",
    "        \n",
    "print('total test: {}'.format(n_test))\n",
    "print('total valid test: {}'.format(len(valid_test_nodes)))\n",
    "\n",
    "# make sure there is no duplication\n",
    "assert(len(valid_test_nodes) == len(set(valid_test_nodes)))\n",
    "\n",
    "# figure out the testId to keep (starting from 0)\n",
    "valid_test_ids = [idx for idx, testId in enumerate(test_indices) if testId in valid_test_nodes]\n",
    "assert(len(valid_test_nodes) == len(valid_test_ids))\n",
    "\n",
    "# filter the test data and labels\n",
    "test_data = data['tx'][valid_test_ids, :]\n",
    "test_labels = data['ty'][valid_test_ids, :]\n",
    "assert(test_data.shape[0] == test_labels.shape[0] == len(valid_test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1983/1983 [00:00<00:00, 2568.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 1983 test: 670\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "# create a conversion from global id to trainId\n",
    "globalId2TrainID = {}\n",
    "for trainId, globalId in enumerate(valid_train_nodes):\n",
    "    globalId2TrainID[globalId] = trainId\n",
    "    \n",
    "# create train graph\n",
    "train_graph = {}\n",
    "for nodeId in tqdm(valid_train_nodes):\n",
    "    assert(nodeId in gp)\n",
    "    vertices = [globalId2TrainID[v] for v in gp[nodeId] if v in set(valid_train_nodes)]\n",
    "    \n",
    "    assert(len(vertices) > 0)\n",
    "    train_graph[globalId2TrainID[nodeId]] = vertices\n",
    "    \n",
    "# create test graph\n",
    "test_graph = {}\n",
    "for testId, nodeId in enumerate(valid_test_nodes):\n",
    "    assert(nodeId in gp)\n",
    "    vertices = [globalId2TrainID[v] for v in gp[nodeId] if v in set(valid_train_nodes)]\n",
    "    \n",
    "    assert(len(vertices) > 0)\n",
    "    test_graph[testId] = vertices # use index starting from 0\n",
    "    \n",
    "assert(len(train_graph) == train_data.shape[0])\n",
    "assert(len(test_graph) == test_data.shape[0])\n",
    "\n",
    "print('train: {} test: {}'.format(train_data.shape[0], test_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodeId: 25 has a self-references. Total connections: 8\n",
      "nodeId: 89 has a self-references. Total connections: 4\n",
      "nodeId: 111 has a self-references. Total connections: 3\n",
      "nodeId: 141 has a self-references. Total connections: 4\n",
      "nodeId: 170 has a self-references. Total connections: 2\n",
      "nodeId: 197 has a self-references. Total connections: 2\n",
      "nodeId: 248 has a self-references. Total connections: 2\n",
      "nodeId: 250 has a self-references. Total connections: 4\n",
      "nodeId: 255 has a self-references. Total connections: 4\n",
      "nodeId: 270 has a self-references. Total connections: 4\n",
      "nodeId: 317 has a self-references. Total connections: 2\n",
      "nodeId: 330 has a self-references. Total connections: 9\n",
      "nodeId: 352 has a self-references. Total connections: 3\n",
      "nodeId: 420 has a self-references. Total connections: 9\n",
      "nodeId: 448 has a self-references. Total connections: 3\n",
      "nodeId: 471 has a self-references. Total connections: 2\n",
      "nodeId: 494 has a self-references. Total connections: 3\n",
      "nodeId: 513 has a self-references. Total connections: 2\n",
      "nodeId: 525 has a self-references. Total connections: 2\n",
      "nodeId: 542 has a self-references. Total connections: 3\n",
      "nodeId: 642 has a self-references. Total connections: 6\n",
      "nodeId: 664 has a self-references. Total connections: 4\n",
      "nodeId: 688 has a self-references. Total connections: 5\n",
      "nodeId: 708 has a self-references. Total connections: 4\n",
      "nodeId: 714 has a self-references. Total connections: 2\n",
      "nodeId: 718 has a self-references. Total connections: 2\n",
      "nodeId: 722 has a self-references. Total connections: 3\n",
      "nodeId: 725 has a self-references. Total connections: 2\n",
      "nodeId: 727 has a self-references. Total connections: 2\n",
      "nodeId: 768 has a self-references. Total connections: 2\n",
      "nodeId: 777 has a self-references. Total connections: 4\n",
      "nodeId: 785 has a self-references. Total connections: 2\n",
      "nodeId: 788 has a self-references. Total connections: 2\n",
      "nodeId: 789 has a self-references. Total connections: 4\n",
      "nodeId: 862 has a self-references. Total connections: 5\n",
      "nodeId: 874 has a self-references. Total connections: 2\n",
      "nodeId: 915 has a self-references. Total connections: 2\n",
      "nodeId: 919 has a self-references. Total connections: 4\n",
      "nodeId: 927 has a self-references. Total connections: 3\n",
      "nodeId: 962 has a self-references. Total connections: 13\n",
      "nodeId: 969 has a self-references. Total connections: 5\n",
      "nodeId: 986 has a self-references. Total connections: 2\n",
      "nodeId: 1000 has a self-references. Total connections: 2\n",
      "nodeId: 1005 has a self-references. Total connections: 3\n",
      "nodeId: 1010 has a self-references. Total connections: 3\n",
      "nodeId: 1040 has a self-references. Total connections: 3\n",
      "nodeId: 1069 has a self-references. Total connections: 2\n",
      "nodeId: 1072 has a self-references. Total connections: 4\n",
      "nodeId: 1089 has a self-references. Total connections: 2\n",
      "nodeId: 1090 has a self-references. Total connections: 2\n",
      "nodeId: 1135 has a self-references. Total connections: 2\n",
      "nodeId: 1165 has a self-references. Total connections: 2\n",
      "nodeId: 1179 has a self-references. Total connections: 2\n",
      "nodeId: 1204 has a self-references. Total connections: 3\n",
      "nodeId: 1206 has a self-references. Total connections: 3\n",
      "nodeId: 1207 has a self-references. Total connections: 3\n",
      "nodeId: 1255 has a self-references. Total connections: 3\n",
      "nodeId: 1271 has a self-references. Total connections: 2\n",
      "nodeId: 1290 has a self-references. Total connections: 2\n",
      "nodeId: 1293 has a self-references. Total connections: 3\n",
      "nodeId: 1305 has a self-references. Total connections: 5\n",
      "nodeId: 1306 has a self-references. Total connections: 2\n",
      "nodeId: 1321 has a self-references. Total connections: 6\n",
      "nodeId: 1328 has a self-references. Total connections: 2\n",
      "nodeId: 1331 has a self-references. Total connections: 2\n",
      "nodeId: 1374 has a self-references. Total connections: 2\n",
      "nodeId: 1400 has a self-references. Total connections: 2\n",
      "nodeId: 1419 has a self-references. Total connections: 3\n",
      "nodeId: 1421 has a self-references. Total connections: 3\n",
      "nodeId: 1518 has a self-references. Total connections: 2\n",
      "nodeId: 1567 has a self-references. Total connections: 11\n",
      "nodeId: 1615 has a self-references. Total connections: 2\n",
      "nodeId: 1620 has a self-references. Total connections: 2\n",
      "nodeId: 1710 has a self-references. Total connections: 5\n",
      "nodeId: 1718 has a self-references. Total connections: 4\n",
      "nodeId: 1761 has a self-references. Total connections: 4\n",
      "nodeId: 1766 has a self-references. Total connections: 3\n",
      "nodeId: 1773 has a self-references. Total connections: 3\n",
      "nodeId: 1795 has a self-references. Total connections: 3\n",
      "nodeId: 1818 has a self-references. Total connections: 3\n",
      "nodeId: 1819 has a self-references. Total connections: 2\n",
      "nodeId: 1863 has a self-references. Total connections: 6\n",
      "nodeId: 1875 has a self-references. Total connections: 2\n",
      "nodeId: 1908 has a self-references. Total connections: 9\n",
      "nodeId: 1957 has a self-references. Total connections: 2\n",
      "nodeId: 1967 has a self-references. Total connections: 2\n"
     ]
    }
   ],
   "source": [
    "# remove self-references\n",
    "for nodeId in train_graph:\n",
    "    connections = train_graph[nodeId]\n",
    "    if nodeId in connections:\n",
    "        if len(connections) == 1:\n",
    "            print(\"nodeId: {} only points to itself.\".format(nodeId))\n",
    "        else:\n",
    "            print(\"nodeId: {} has a self-references. Total connections: {}\".format(nodeId, len(connections)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the graph is symmetric\n",
    "for nodeId in train_graph:\n",
    "    connections = train_graph[nodeId]\n",
    "    for nn_nodeId in connections:\n",
    "        if nodeId not in train_graph[nn_nodeId]:\n",
    "            print(\"there is connection from {} to {}.\".format(nn_nodeId, nodeId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[544]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_graph[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_graph[544]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels to a sparse matrix format\n",
    "import sklearn.preprocessing\n",
    "from scipy import sparse\n",
    "\n",
    "train_labels = np.argmax(train_labels, axis=1)\n",
    "test_labels = np.argmax(test_labels, axis=1)\n",
    "\n",
    "n_classes = np.max(train_labels) - np.min(train_labels) + 1\n",
    "\n",
    "label_binarizer = sklearn.preprocessing.LabelBinarizer()\n",
    "label_binarizer.fit(range(n_classes))\n",
    "\n",
    "gnd_train = label_binarizer.transform(train_labels)\n",
    "gnd_test = label_binarizer.transform(test_labels)\n",
    "gnd_train = sparse.csr_matrix(gnd_train)\n",
    "gnd_test = sparse.csr_matrix(gnd_test)\n",
    "\n",
    "print(gnd_train.shape)\n",
    "print(gnd_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a connection matrix\n",
    "n_train = train_data.shape[0]\n",
    "train_connections = np.zeros((n_train, n_train), dtype=int)\n",
    "for doc_id in train_graph:\n",
    "    train_connections[doc_id][train_graph[doc_id]] = 1\n",
    "train_connections = sparse.csr_matrix(train_connections)\n",
    "\n",
    "n_test = test_data.shape[0]\n",
    "test_connections = np.zeros((n_test, n_train), dtype=int)\n",
    "for doc_id in test_graph:\n",
    "    test_connections[doc_id][test_graph[doc_id]] = 1\n",
    "test_connections = sparse.csr_matrix(test_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join('../datasets/clean', dataset_name)\n",
    "##########################################################################################\n",
    "\n",
    "train = []\n",
    "for doc_id in train_graph:\n",
    "    doc = {'doc_id': doc_id, 'bow': train_data[doc_id], \n",
    "           'label': gnd_train[doc_id], 'neighbors': train_connections[doc_id]}\n",
    "    train.append(doc)\n",
    "\n",
    "train_df = pd.DataFrame.from_dict(train)\n",
    "train_df.set_index('doc_id', inplace=True)\n",
    "\n",
    "fn = os.path.join(save_dir, '{}.train.pkl'.format(dataset_name))\n",
    "train_df.to_pickle(fn)\n",
    "##########################################################################################\n",
    "\n",
    "test = []\n",
    "for doc_id in test_graph:\n",
    "    doc = {'doc_id': doc_id, 'bow': test_data[doc_id], \n",
    "           'label': gnd_test[doc_id], 'neighbors': test_connections[doc_id]}\n",
    "    test.append(doc)\n",
    "\n",
    "test_df = pd.DataFrame.from_dict(test)\n",
    "test_df.set_index('doc_id', inplace=True)\n",
    "\n",
    "fn = os.path.join(save_dir, '{}.test.pkl'.format(dataset_name))\n",
    "test_df.to_pickle(fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Research2018",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
